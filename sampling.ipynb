{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sampling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOyho3j0jSohWwJoJ2tzjNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jason-jiankai/sampling/blob/master/sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePd7ysSKsfE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "# import ssl\n",
        "# ssl._create_default_https_context = ssl._create_unverified_context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzkZJsfstMuw",
        "colab_type": "text"
      },
      "source": [
        "# Dataset\n",
        "cifar10, with 50000 training examples, 10000 test examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MckGDr5b1P7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "train, test = cifar10.load_data()\n",
        "# 50000, 10000\n",
        "\n",
        "train = train[0] / 255.0, train[1]\n",
        "test = test[0] / 255.0, test[1]\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VRydDFWtloq",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "define a CNN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdXBxE3c1og6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                             kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
        "                             input_shape=(32, 32, 3)),\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
        "                             kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu',\n",
        "                             kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Xa2BrmKtzt7",
        "colab_type": "text"
      },
      "source": [
        "# Shuffling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDpjKyVc1UpH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7237dc58-2c7b-478d-c0af-59500110f8eb"
      },
      "source": [
        "shuffle_test_dataset = test_dataset.batch(50).repeat()\n",
        "\n",
        "t1_shuffle = time.time()\n",
        "shuffle_train_dataset = train_dataset.shuffle(10000).batch(50).repeat()\n",
        "t2_shuffle = time.time()\n",
        "print(\"shuffling takes\", t2_shuffle-t1_shuffle, \"seconds\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shuffling takes 0.0012438297271728516 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtGuCcFW1uxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ad3396c1-3cb0-49ec-96fd-fd1fdecf065d"
      },
      "source": [
        "model_shuffle = model()\n",
        "\n",
        "t3_shuffle = time.time()\n",
        "model_shuffle.fit(\n",
        "  shuffle_train_dataset,\n",
        "  steps_per_epoch = 1000,\n",
        "  validation_data = shuffle_test_dataset,\n",
        "  validation_steps = 200,\n",
        "  epochs = 10\n",
        ")\n",
        "t4_shuffle = time.time()\n",
        "print(\"training based on shuffling takes\", t4_shuffle-t3_shuffle, \"seconds\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 1.7592 - accuracy: 0.3728 - val_loss: 1.4586 - val_accuracy: 0.4909\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.4342 - accuracy: 0.5085 - val_loss: 1.3004 - val_accuracy: 0.5730\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3010 - accuracy: 0.5708 - val_loss: 1.1620 - val_accuracy: 0.6208\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.2239 - accuracy: 0.6033 - val_loss: 1.1350 - val_accuracy: 0.6370\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.1662 - accuracy: 0.6299 - val_loss: 1.0825 - val_accuracy: 0.6575\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.1312 - accuracy: 0.6467 - val_loss: 1.0540 - val_accuracy: 0.6693\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.0983 - accuracy: 0.6582 - val_loss: 1.0233 - val_accuracy: 0.6879\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.0703 - accuracy: 0.6704 - val_loss: 1.0073 - val_accuracy: 0.6947\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.0530 - accuracy: 0.6796 - val_loss: 1.0517 - val_accuracy: 0.6785\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.0353 - accuracy: 0.6846 - val_loss: 0.9894 - val_accuracy: 0.7068\n",
            "training based on shuffling takes 53.32881045341492 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2AhMYA5t9y4",
        "colab_type": "text"
      },
      "source": [
        "# SWO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLFh9bQr8Jvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batches_by_swo(dataset, dataset_size, batch_size, steps, test_mode = False):\n",
        "    indexes = []\n",
        "    for s in range(steps):\n",
        "        indexes.append(np.sort(np.random.choice(dataset_size, size=batch_size, replace=False)))\n",
        "\n",
        "    returned_indexes = indexes.copy()\n",
        "\n",
        "    i = 0\n",
        "    batch_features = [[] for _ in range(steps)]\n",
        "    batch_labels = [[] for _ in range(steps)]\n",
        "    for e in dataset.as_numpy_iterator():\n",
        "      for s in range(steps):\n",
        "          if indexes[s].size > 0 and i == indexes[s][0]:\n",
        "              indexes[s] = indexes[s][1:]\n",
        "              batch_features[s].append(e[0])\n",
        "              batch_labels[s].append(e[1])\n",
        "      i += 1\n",
        "      if i % 5000 == 0: print('{:.2f}%'.format(float(i)/50000*100))\n",
        "    print(\"transforming data to dataset object\")\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((batch_features, batch_labels))\n",
        "    if not test_mode:\n",
        "      return dataset\n",
        "    else:\n",
        "      return dataset, returned_indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSRSH7QT8RVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "25a8d005-416f-4248-e1d1-d6f5787702d4"
      },
      "source": [
        "swo_test_dataset = test_dataset.batch(50).repeat()\n",
        "\n",
        "t1_swo = time.time()\n",
        "swo_train_dataset = generate_batches_by_swo(train_dataset, 50000, 50, 1000).repeat()\n",
        "t2_swo = time.time()\n",
        "print(\"swo takes\", t2_swo-t1_swo, \"seconds\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.00%\n",
            "20.00%\n",
            "30.00%\n",
            "40.00%\n",
            "50.00%\n",
            "60.00%\n",
            "70.00%\n",
            "80.00%\n",
            "90.00%\n",
            "100.00%\n",
            "transforming data to dataset object\n",
            "swo takes 80.2788462638855 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7dg999w8osx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ec653019-5017-422b-dcd5-e1365e1db981"
      },
      "source": [
        "model_swo = model()\n",
        "\n",
        "t3_swo = time.time()\n",
        "model_swo.fit(\n",
        "    swo_train_dataset,\n",
        "    steps_per_epoch=1000,\n",
        "    validation_data = swo_test_dataset,\n",
        "    validation_steps = 200,\n",
        "    epochs=10\n",
        ")\n",
        "t4_swo = time.time()\n",
        "print(\"training based on swo takes\", t4_swo-t3_swo, \"seconds\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7745 - accuracy: 0.3575 - val_loss: 1.5556 - val_accuracy: 0.4671\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4156 - accuracy: 0.5162 - val_loss: 1.3740 - val_accuracy: 0.5434\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2916 - accuracy: 0.5736 - val_loss: 1.2427 - val_accuracy: 0.5929\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2086 - accuracy: 0.6101 - val_loss: 1.2695 - val_accuracy: 0.5969\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.1496 - accuracy: 0.6357 - val_loss: 1.2256 - val_accuracy: 0.6193\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.1054 - accuracy: 0.6561 - val_loss: 1.1246 - val_accuracy: 0.6485\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0686 - accuracy: 0.6688 - val_loss: 1.0826 - val_accuracy: 0.6680\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0461 - accuracy: 0.6792 - val_loss: 1.1305 - val_accuracy: 0.6530\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0209 - accuracy: 0.6885 - val_loss: 1.0555 - val_accuracy: 0.6772\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0047 - accuracy: 0.6955 - val_loss: 1.0496 - val_accuracy: 0.6841\n",
            "training based on swo takes 39.21904110908508 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfxy8QwsuCGe",
        "colab_type": "text"
      },
      "source": [
        "# Poisson"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFboiJvwbfB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batches_by_poisson(dataset, dataset_size, batch_size, steps, test_mode = False):\n",
        "    ratio = float(batch_size) / dataset_size\n",
        "    \n",
        "    indexes = []\n",
        "    for _ in range(steps):\n",
        "      pros = np.random.uniform(0,1,dataset_size)\n",
        "      chosen = [i for i in range(dataset_size) if pros[i] < ratio]\n",
        "      indexes.append(chosen)\n",
        "    \n",
        "    returned_indexes = indexes.copy()\n",
        "\n",
        "    i = 0\n",
        "    batch_features = [[] for _ in range(steps)]\n",
        "    batch_labels = [[] for _ in range(steps)]\n",
        "    for e in dataset.as_numpy_iterator():\n",
        "      for s in range(steps):\n",
        "          if indexes[s] != [] and i == indexes[s][0]:\n",
        "              indexes[s] = indexes[s][1:]\n",
        "              batch_features[s].append(e[0])\n",
        "              batch_labels[s].append(e[1])\n",
        "      i += 1\n",
        "      if i % 5000 == 0: print('{:.2f}%'.format(float(i)/50000*100))\n",
        "    \n",
        "    batch = [(features, labels) for features, labels in zip(batch_features,batch_labels)]\n",
        "\n",
        "    print(\"transforming data to dataset object\")\n",
        "\n",
        "    features_shape = [None, 32, 32, 3]\n",
        "    labels_shape = [None, 1]\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        lambda: batch,\n",
        "        (tf.float32, tf.float32),\n",
        "        (features_shape, labels_shape)\n",
        "    )\n",
        "\n",
        "    if not test_mode:\n",
        "      return dataset\n",
        "    else:\n",
        "      return dataset, returned_indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1msChveb0m6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ed56a06d-0abe-4b5d-8049-18e45fd53b47"
      },
      "source": [
        "poisson_test_dataset = test_dataset.batch(50).repeat()\n",
        "\n",
        "t1_poisson = time.time()\n",
        "poisson_train_dataset = generate_batches_by_poisson(train_dataset, 50000, 50, 1000).repeat()\n",
        "t2_poisson = time.time()\n",
        "print(\"swo takes\", t2_poisson-t1_poisson, \"seconds\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.00%\n",
            "20.00%\n",
            "30.00%\n",
            "40.00%\n",
            "50.00%\n",
            "60.00%\n",
            "70.00%\n",
            "80.00%\n",
            "90.00%\n",
            "100.00%\n",
            "transforming data to dataset object\n",
            "swo takes 25.269413709640503 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aImGZTWdlKVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "2298c524-b5ec-4f16-c0e2-6c9ed5f3f5ca"
      },
      "source": [
        "model_poisson = model()\n",
        "\n",
        "t3_poisson = time.time()\n",
        "model_poisson.fit_generator(\n",
        "    poisson_train_dataset,\n",
        "    steps_per_epoch=1000,\n",
        "    validation_data = poisson_test_dataset,\n",
        "    validation_steps = 200,\n",
        "    epochs=10\n",
        ")\n",
        "t4_poisson = time.time()\n",
        "print(\"training based on poisson takes\", t4_poisson-t3_poisson, \"seconds\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-02898ba81e0a>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 1.7534 - accuracy: 0.3799 - val_loss: 1.4243 - val_accuracy: 0.5144\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.4041 - accuracy: 0.5268 - val_loss: 1.2791 - val_accuracy: 0.5817\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.2744 - accuracy: 0.5831 - val_loss: 1.2116 - val_accuracy: 0.6127\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.1857 - accuracy: 0.6221 - val_loss: 1.1221 - val_accuracy: 0.6514\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.1391 - accuracy: 0.6469 - val_loss: 1.0968 - val_accuracy: 0.6642\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.0926 - accuracy: 0.6653 - val_loss: 1.0854 - val_accuracy: 0.6738\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.0626 - accuracy: 0.6815 - val_loss: 1.1121 - val_accuracy: 0.6632\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.0307 - accuracy: 0.6923 - val_loss: 1.0451 - val_accuracy: 0.6943\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.0117 - accuracy: 0.6991 - val_loss: 1.0171 - val_accuracy: 0.7023\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9899 - accuracy: 0.7103 - val_loss: 1.0115 - val_accuracy: 0.7064\n",
            "training based on poisson takes 50.22898983955383 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOEuiVG6SzC0",
        "colab_type": "text"
      },
      "source": [
        "# Time Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egxfKBS5uJZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2a0c3061-9a14-4e3a-b8ac-445b685f8f73"
      },
      "source": [
        "shuffle_time = t2_shuffle-t1_shuffle + t4_shuffle-t3_shuffle\n",
        "swo_time = t2_swo-t1_swo + t4_swo-t3_swo\n",
        "poisson_time = t2_poisson-t1_poisson + t4_poisson-t3_poisson\n",
        "\n",
        "print(\n",
        "    \"training based on shuffling takes\", shuffle_time, \"seconds: \\nincluding preparing dataset time\",\n",
        "    t2_shuffle-t1_shuffle, \"seconds, and training time\", t4_shuffle-t3_shuffle, \"seconds.\\n\"\n",
        ")\n",
        "print(\n",
        "    \"training based on swo takes\", swo_time, \"seconds: \\nincluding preparing dataset time\",\n",
        "    t2_swo-t1_swo, \"seconds, and training time\", t4_swo-t3_swo, \"seconds.\\n\"\n",
        ")\n",
        "print(\n",
        "    \"training based on poisson takes\", poisson_time, \"seconds: \\nincluding preparing dataset time\",\n",
        "    t2_poisson-t1_poisson, \"seconds, and training time\", t4_poisson-t3_poisson, \"seconds.\\n\"\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training based on shuffling takes 53.33005428314209 seconds: \n",
            "including preparing dataset time 0.0012438297271728516 seconds, and training time 53.32881045341492 seconds.\n",
            "\n",
            "training based on swo takes 119.49788737297058 seconds: \n",
            "including preparing dataset time 80.2788462638855 seconds, and training time 39.21904110908508 seconds.\n",
            "\n",
            "training based on poisson takes 75.49840354919434 seconds: \n",
            "including preparing dataset time 25.269413709640503 seconds, and training time 50.22898983955383 seconds.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2iX7-kqvIga",
        "colab_type": "text"
      },
      "source": [
        "Basically, training based on shuffling and sampling methods have similar accuracies, about 70%.\n",
        "\n",
        "For a dataset of 50000, it takes \"swo\" 86 seconds to prepare the dataset, and takes \"poisson\" 25 seconds to prepare the dataset. As a comparison, shuffling only takes 0.001 seconds.\n",
        "\n",
        "Poisson takes less time because it uses a generator, which generate batches during training and takes less space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-yojkLq73fq",
        "colab_type": "text"
      },
      "source": [
        "# **Test**\n",
        "test whether swo and poisson sampling methods perform normal:\n",
        "*   whether swo and poisson generate enough batches, 1000 in this case\n",
        "*   whether swo and poisson generate batches of correct shapes\n",
        "  *   swo has shape of (50, 32, 32, 3)\n",
        "  *   poisson has shape of (viriable size around 50, 32, 32, 3)\n",
        "*   whether swo and poisson can appropriately sample examples from the dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjePW2H8IZb",
        "colab_type": "text"
      },
      "source": [
        "##swo test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sbA2ulb76Mn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8990f422-7f9d-4ba8-b337-abeede46fec7"
      },
      "source": [
        "swo_train_dataset_2, swo_indexes = generate_batches_by_swo(train_dataset, 50000, 50, 1000, test_mode=True)\n",
        "swo_train_dataset_2"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.00%\n",
            "20.00%\n",
            "30.00%\n",
            "40.00%\n",
            "50.00%\n",
            "60.00%\n",
            "70.00%\n",
            "80.00%\n",
            "90.00%\n",
            "100.00%\n",
            "transforming data to dataset object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((50, 32, 32, 3), (50, 1)), types: (tf.float64, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HokHgKa-GLj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "539f239e-c059-4cb5-bbca-c856b7838d9e"
      },
      "source": [
        "batch_num = 0\n",
        "for _ in swo_train_dataset_2.as_numpy_iterator():\n",
        "  batch_num += 1\n",
        "print(batch_num)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07f1wIKsI5B3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1bd945fb-e728-4ab6-a419-a6fde75d3454"
      },
      "source": [
        "for s in swo_train_dataset_2.take(3).as_numpy_iterator():\n",
        "  print(\"batch features shape:\", np.shape(s[0]), \"batch labels shape:\", np.shape(s[1]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch features shape: (50, 32, 32, 3) batch labels shape: (50, 1)\n",
            "batch features shape: (50, 32, 32, 3) batch labels shape: (50, 1)\n",
            "batch features shape: (50, 32, 32, 3) batch labels shape: (50, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUxF5-CjOMhG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "d01a7468-0d39-4ee0-9b73-fea170234de4"
      },
      "source": [
        "for ind in swo_indexes[:3]:\n",
        "  print(ind)\n",
        "  print()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1101  1242  2983  3095  3262  3466  5958  6850  6912  7258  9966 10680\n",
            " 11946 12450 13435 13985 14453 17849 19762 20126 20380 23634 24844 25650\n",
            " 25809 26342 27983 31742 32042 33214 33405 33978 34388 34954 37519 38839\n",
            " 42529 42999 44870 46059 46089 46225 47282 47730 49137 49259 49326 49341\n",
            " 49603 49846]\n",
            "\n",
            "[  916  1676  3987  4044  4172  4569  6827  7537  7721  8250 11195 11544\n",
            " 12546 12771 15223 16146 16451 17333 18671 19095 19917 20609 21778 22603\n",
            " 23929 24008 24286 26123 27261 31304 31760 31766 33264 33599 35116 36503\n",
            " 38045 40159 40202 41206 41555 45777 45995 46788 47129 47203 48812 48893\n",
            " 48943 49667]\n",
            "\n",
            "[ 2558  2842  4606  5310  5844  8399  8424  8494  8586 10731 11442 14133\n",
            " 15015 15397 17295 18656 18666 20009 21724 26281 26498 27333 27728 29479\n",
            " 29719 29872 30825 31493 31587 31645 33215 33752 34333 34590 40282 40296\n",
            " 40359 41504 41523 41821 42212 43496 44323 45450 45898 46461 48604 49040\n",
            " 49728 49849]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq7-XGgK8pyw",
        "colab_type": "text"
      },
      "source": [
        "so, each batch has 50 examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_cBInvZ8L9H",
        "colab_type": "text"
      },
      "source": [
        "##poisson test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MZPWXZ48CJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3c4cdca8-6537-4bf2-c9ee-6cb4df6cc3e4"
      },
      "source": [
        "poisson_train_dataset_2, poisson_indexes = generate_batches_by_poisson(train_dataset, 50000, 50, 1000, test_mode=True)\n",
        "poisson_train_dataset_2"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.00%\n",
            "20.00%\n",
            "30.00%\n",
            "40.00%\n",
            "50.00%\n",
            "60.00%\n",
            "70.00%\n",
            "80.00%\n",
            "90.00%\n",
            "100.00%\n",
            "transforming data to dataset object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FlatMapDataset shapes: ((None, 32, 32, 3), (None, 1)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dR23esn8wSQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7f6012a-a0f5-420f-f643-38743e21bd3d"
      },
      "source": [
        "batch_num = 0\n",
        "for p in poisson_train_dataset_2.as_numpy_iterator():\n",
        "  batch_num += 1\n",
        "print(batch_num)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s55tnOVwKPmN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bf8c00e9-4ebb-4b53-e6eb-0d5b0816f691"
      },
      "source": [
        "for p in poisson_train_dataset_2.take(5).as_numpy_iterator():\n",
        "  print(\"batch features shape:\", np.shape(p[0]), \"batch labels shape:\", np.shape(p[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch features shape: (53, 32, 32, 3) batch labels shape: (53, 1)\n",
            "batch features shape: (56, 32, 32, 3) batch labels shape: (56, 1)\n",
            "batch features shape: (52, 32, 32, 3) batch labels shape: (52, 1)\n",
            "batch features shape: (58, 32, 32, 3) batch labels shape: (58, 1)\n",
            "batch features shape: (51, 32, 32, 3) batch labels shape: (51, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXAqNh5NQ033",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "24d09acf-8893-4ef5-8f73-dca8f209940b"
      },
      "source": [
        "for ind in poisson_indexes[:3]:\n",
        "  print(np.array(ind))\n",
        "  print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  260  3051  3060  3511  6225  7340  8629  8658  9662 11777 11828 12332\n",
            " 13033 13351 13888 14814 14975 16707 17518 18186 18327 18457 18912 19918\n",
            " 23041 23158 24729 25082 25112 26425 28395 28525 31923 32684 32716 34575\n",
            " 34596 37157 37705 38507 39045 41119 41525 42353 42547 44102 44111 44959\n",
            " 45284 45955 46674 48709 49938]\n",
            "\n",
            "[  120  1227  3352  4073  6329  8218  9701 10331 10809 12942 13288 13337\n",
            " 16513 16787 16961 17536 17673 19012 19315 19381 21008 21544 21783 22281\n",
            " 22376 23710 25367 26164 26669 26833 28332 28550 28930 29701 30621 31449\n",
            " 31560 32811 34474 35087 35133 37049 37056 37650 42115 42508 43548 44218\n",
            " 45484 45638 45940 46649 47149 47467 48507 49196]\n",
            "\n",
            "[  394   599  2223  2249  2297  2533  3570  3746  6794  6856  7351  8089\n",
            "  8629  8868 10657 10790 13666 19423 19547 19579 22063 22236 22332 23658\n",
            " 23865 23906 25528 28767 30390 30413 30856 31386 32624 33544 34015 34767\n",
            " 34808 35055 35706 36945 36976 38798 40214 43899 45676 45680 46328 46500\n",
            " 46613 46794 47750 47830]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}